{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.signal import spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input/output directories\n",
    "base_path = r\"C:\\Users\\lenovo\\thesis\\classification\\csv\"\n",
    "output_path=  r\"C:\\Users\\lenovo\\thesis\\classification\\stats\"\n",
    "\n",
    "input_files = [\n",
    "    output_path+\"\\\\B007_1_123\\\\X123_DE_time.csv\",      \n",
    "    output_path+\"\\\\B014_1_190\\\\B014_1_190X190_DE_time.csv\",\n",
    "    output_path+\"\\\\B021_1_227\\\\B021_1_227X227_DE_time.csv\",\n",
    "    \n",
    "    output_path+\"\\\\OR007_6_1_136\\\\X136_DE_time.csv\",\n",
    "    output_path+\"\\\\OR014_6_1_202\\\\OR014_6_1_202X202_DE_time.csv\",\n",
    "    output_path+\"\\\\OR021_6_1_239\\\\OR021_6_1_239X239_DE_time.csv\",\n",
    "\n",
    "    output_path+\"\\\\IR007_1_110\\\\X110_DE_time.csv\",\n",
    "    output_path+\"\\\\IR014_1_175\\\\IR014_1_175X175_DE_time.csv\",\n",
    "    output_path+\"\\\\IR021_1_214\\\\IR021_1_214X214_DE_time.csv\",\n",
    "    \n",
    "]\n",
    "\n",
    "output_directories = [\n",
    "   output_path+\"\\\\bopolar7\",\n",
    "   output_path+\"\\\\bopolar14\"\n",
    "   output_path+\"\\\\bopolar21\"\n",
    "   output_path+\"\\\\orpolar7\",\n",
    "   output_path+\"\\\\orpolar14\"\n",
    "   output_path+\"\\\\orpolar21\"\n",
    "   output_path+\"\\\\irpolar7\",\n",
    "   output_path+\"\\\\irpolar14\"\n",
    "   output_path+\"\\\\irpolar21\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5256d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean,rms,max,variance,skewness,kurtosis\n",
    "def calculate_statistical_features(data):\n",
    "    mean = np.mean(data)\n",
    "    rms = np.sqrt(np.mean(data**2))\n",
    "    standard_deviation = np.std(data)\n",
    "    maximum = np.max(data)\n",
    "    \n",
    "    variance = np.var(data)\n",
    "    skewness = moment(data, moment=3) / np.power(variance, 3/2) if variance > 0 else 0\n",
    "    kurtosis = moment(data, moment=4) / np.power(variance, 2) if variance > 0 else 0\n",
    "\n",
    "    return mean, rms, standard_deviation, skewness, kurtosis, maximum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb0f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save statistical features based on the splitted signals\n",
    "def process_chunk(chunk_data, output_path):\n",
    "    \n",
    "    features = calculate_statistical_features(chunk_data)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Mean': [features[0]],\n",
    "        'RMS': [features[1]],\n",
    "        'Standard Deviation': [features[2]],\n",
    "        'Skewness': [features[3]],\n",
    "        'Kurtosis': [features[4]],\n",
    "        'Maximum': [features[5]]\n",
    "    })\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91464025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the signals to samples with 4800 datapoints with 50% overlap\n",
    "def process_dataset(input_file, expected_freq, output_directory, chunk_size=4800, overlap=0.5):\n",
    "    fs = 48000\n",
    "\n",
    "    dataset = pd.read_csv(input_file, header=None)\n",
    "    data = dataset.iloc[:, 0].values \n",
    "\n",
    "    nsamples = len(data)\n",
    "    overlaps = int(chunk_size * overlap)\n",
    "    nchunks = (nsamples - chunk_size) // overlaps + 1\n",
    "\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    for j in range(nchunks):\n",
    "        startid = j * overlaps\n",
    "        endid = startid + chunk_size\n",
    "        chunk_data = data[startid:endid]\n",
    "\n",
    "        file_name = f\"chunk{j + 1}_polar_spectrum.png\"\n",
    "        output_path = os.path.join(output_directory, file_name)\n",
    "\n",
    "        # create stats csv\n",
    "        process_chunk(chunk_data, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b2046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_file, output_directory in zip(input_files, output_directories):\n",
    "    process_dataset(input_file, output_directory, chunk_size=4800, overlap=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
